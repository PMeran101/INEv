{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will document what happens when executing conflicting_qwl.sh \n",
    "\n",
    "\n",
    "<h3>generate_network.py</h3>\n",
    "The frist thing happening will be to generate the Network with parameters 20 0.5 1.3 and $h (6 10 ...)\n",
    "\n",
    "Several parameters are changable by the user. These are:\n",
    "Network Size,\n",
    "Node Event Ratio,\n",
    "Eventskew,\n",
    "Number of Eventtypes\n",
    "\n",
    "2. Eventrates will be created using numpy np.random.zipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Eventrates\n",
      "----------------------\n",
      "[629   3  10  14   1   1]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Generating Eventrates\")\n",
    "print(\"----------------------\")\n",
    "eventrates = np.random.zipf(1.3, 6)\n",
    "print(eventrates)\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards we will create our random hierarchical network tree using our node class.\n",
    "1. Loop through 1 - Networksize\n",
    "-> Random Computing power and Memory will be assigned to each network node\n",
    "2. Each node gets assigned a random parent in the network and siblings are assigned\n",
    "3. After all nodes are created and assigned we will add each leaf node (no childrens) a eventrate like following (random distribution for which events are generated)\n",
    "-> The non Leaf nodes will receive an list with 0 * len(eventrates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 10, 14, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "n_e_r = 0.5\n",
    "myevents = []\n",
    "for i in range(len(eventrates)):\n",
    "    x = np.random.uniform(0,1)\n",
    "    if x < n_e_r:\n",
    "        myevents.append(eventrates[i])\n",
    "    else:\n",
    "        myevents.append(0)\n",
    "\n",
    "print(myevents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After succsefull generation of Network Tree we create 2 binarie files:\n",
    "- Create networkExperimentData\n",
    "    - Array of Eventskew (1.3), number of eventtypes (6), node event ratio (0.5), Min(eventrates)/Max(eventrates)\n",
    "- Create network\n",
    "    - save the network array of nodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>generate_graph.py</h3>\n",
    "\n",
    "First we will use network binary and then create a networkX Graph\n",
    "and then create a fog graph using the root node.\n",
    "In this we only iterate from the root node to the bottom and add the the correct nodes and edges to one another\n",
    "\n",
    "\n",
    "<h3>allpairs.py</h3>\n",
    "\n",
    "in this code we take a look at all nodes and compute the shortest distance from each node to all nodes using the dijkstra algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a list of empty distances between each node\n",
      "----------------\n",
      "[[], [], [], [], [], [], [], [], [], []]\n",
      "----------------\n",
      "Here are the distances between all nodes to one another\n",
      "----------------\n",
      "[[0, 1, 1, 1, 2, 2, 2, 1, 1, 2], [1, 0, 2, 2, 1, 3, 1, 2, 2, 3], [1, 2, 0, 2, 3, 3, 3, 2, 2, 3], [1, 2, 2, 0, 3, 1, 3, 2, 2, 3], [2, 1, 3, 3, 0, 4, 2, 3, 3, 4], [2, 3, 3, 1, 4, 0, 4, 3, 3, 4], [2, 1, 3, 3, 2, 4, 0, 3, 3, 4], [1, 2, 2, 2, 3, 3, 3, 0, 2, 1], [1, 2, 2, 2, 3, 3, 3, 2, 0, 3], [2, 3, 3, 3, 4, 4, 4, 1, 3, 0]]\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import multiprocessing\n",
    "import time\n",
    "import networkx as nx \n",
    "\n",
    "with open('graph',  'rb') as graph_file:\n",
    "    G = pickle.load(graph_file)\n",
    "\n",
    "myNodes = list(G.nodes)\n",
    "allPairs = [[] for x in myNodes]\n",
    "print(\"Printing a list of empty distances between each node\")\n",
    "print(\"----------------\")\n",
    "print(allPairs)\n",
    "print(\"----------------\")\n",
    "\n",
    "def fillMyMatrice(me):  \n",
    "    myDistances = []\n",
    "    for j in range(len(G.nodes)):            \n",
    "           myDistances.append(len(nx.shortest_path(G, me, j, method='dijkstra')) - 1)   \n",
    "    return (me, myDistances)\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "         \n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = pool.map(fillMyMatrice, myNodes)\n",
    "for i in result:\n",
    "    allPairs[i[0]] = i[1]\n",
    "end = time.time()\n",
    "print(\"Here are the distances between all nodes to one another\")\n",
    "print(\"----------------\")\n",
    "print(allPairs)\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to generate the Query workload \n",
    "\n",
    "<h3>generate_qwls.py</h3>\n",
    "\n",
    "First we call the generate_workload function with count=3 and length=5\n",
    "It creates random queries between SEQ and AND operations.\n",
    "The children being the Primitive Events or subqueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tree.SEQ object at 0x7f6cf82abdf0>, <tree.AND object at 0x7f6cf9d54ca0>, <tree.AND object at 0x7f6ce1b73a00>]\n",
      "[<tree.PrimEvent object at 0x7f6cf9d5d4c0>, <tree.PrimEvent object at 0x7f6cf8338340>, <tree.PrimEvent object at 0x7f6cd0386850>]\n",
      "[<tree.PrimEvent object at 0x7f6cf8285580>, <tree.SEQ object at 0x7f6cf8398460>]\n",
      "[<tree.PrimEvent object at 0x7f6ce1b73a60>, <tree.SEQ object at 0x7f6ce1b73cd0>]\n"
     ]
    }
   ],
   "source": [
    "with open('current_wl', 'rb') as current_wl:\n",
    "    cwl = pickle.load(current_wl)\n",
    "    print(cwl)\n",
    "    for i in cwl:\n",
    "        print(i.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the Queries we dump into into a binary file\n",
    "- Create current_wl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>generate_selectivity.py</h3>\n",
    "generates selectivities for a given tuple of primitve event types\n",
    "first uses the network binary to create a List of primitive events (Letters)\n",
    "the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, 0, 0, 73, 11, 4, 0, 0, 0, 0, 0, 0, 0, 0, 99071, 0, 66, 17, 11]\n",
      "['A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "with open('network',  'rb') as  nw_file:\n",
    "        nw = pickle.load(nw_file)\n",
    "    \n",
    "PrimitiveEvents = list(string.ascii_uppercase[:3])\n",
    "\n",
    "print(nw[5].eventrates)\n",
    "print(PrimitiveEvents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initilization of Primitive Eventtypes the selectivities for each tuple is created. A function receives the list of primitive Events and 2 parameters\n",
    "x = 0.1 and y=0.01\n",
    "1. Generate all possible combinations of Primitive Events\n",
    "2. assign selectivities to each pair of Primitive Events\n",
    "    - selectivities are calculated randomly either as 1 or a random number calculated through random.uniform(0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AC', 'AB', 'CB']\n",
      "0.03937781862900642\n"
     ]
    }
   ],
   "source": [
    "from helper import generate_twosets\n",
    "print(generate_twosets(PrimitiveEvents))\n",
    "\n",
    "import random as rd\n",
    "\n",
    "print(rd.uniform(0.1,0.01))\n",
    "#initialize_selectivities(PrimitiveEvents,0.1,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating all selectivities \n",
    "- Create selectivitiesExperimentData\n",
    "    - Array of [0.1 and median of all selectivities]\n",
    "- Create selectivities\n",
    "    - Dumping the dictionary of all selectivities into a file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>write_config_single.py</h3>\n",
    "\n",
    "writes into a .txt file\n",
    "- Network structure\n",
    "- Query workload\n",
    "- Example MuSE graph query\n",
    "- Selectivitiy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>determine_all_single_selectivities.py</h3>\n",
    "\n",
    "1. Opens the config_single_selectivity.txt\n",
    "2. Opens the Workload (Queries)\n",
    "3. Iterates over the Queries and generates selectivities for each Primitive Events and the corresponding queries (for example SEQ(P,I,O))\n",
    "4. creates singleSelectivities binary file with these selectivities of projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>gemerate_projections.py</h3>\n",
    "\n",
    "1. Iterates over the workload binaries (current_wl) and generates beneficial for each projection\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SEQ(P, I, O)\n",
      "P\n",
      "I\n",
      "O\n",
      "SEQ(I, O)\n",
      "SEQ(P, I, O)\n",
      "SEQ(I, O)\n",
      "(0.08071676233790777, 4.681572215598651)\n",
      "SEQ(P, I, O)\n",
      "(0.005948036949143954, 34178.12217814116)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('current_wl','rb') as queries:\n",
    "    cwl = pickle.load(queries)\n",
    "    # print(cwl)\n",
    "    # for i in cwl:\n",
    "    #     print(i.children)\n",
    "from generate_projections import generate_projections\n",
    "\n",
    "my_quer = cwl[0]\n",
    "print(f\"Query: {my_quer}\")\n",
    "prim_events = my_quer.children\n",
    "\n",
    "for i in prim_events:\n",
    "    print(i)\n",
    "\n",
    "result = generate_projections(cwl[0])\n",
    "for i in result:\n",
    "    for j in i:\n",
    "        print(j)    \n",
    "        try:\n",
    "            print(i[j])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First all Queries are iterated over then possible projections are generated. Each projection gets attached a selectivity and a rate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>combigen.py</h3>\n",
    "\n",
    "This is where the optimizing happens of the queries\n",
    "\n",
    "Binaries are created\n",
    "- Creates curcombi\n",
    "- Creates originalCombiDict\n",
    "- Creates criticalMSTypes\n",
    "- Creates filterDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ(P, I, O)\n",
      "{}\n",
      "['P']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from generate_projections import projsPerQuery\n",
    "\n",
    "with open('current_wl','rb') as workload:\n",
    "    query = pickle.load(workload)\n",
    "\n",
    "print(query[0])\n",
    "from combigen import MSoptionsPerEvent, extractMsOptions, getBestChainCombis, promisingChainProjection\n",
    "msoptions = MSoptionsPerEvent(query[0])\n",
    "extracted = extractMsOptions(query[0])\n",
    "promisingChain = promisingChainProjection(query[0])\n",
    "print(promisingChain)\n",
    "print(extracted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curcombi will be my combination of projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(991975.0, 0, 2, {'P': {'P2': [2, 0], 'P4': [4, 1, 0], 'P5': [5, 3, 0], 'P6': [6, 1, 0], 'P8': [8, 0], 'P9': [9, 7, 0]}, 'I': {'I6': [6, 1, 0]}, 'O': {'O2': [2, 0], 'O4': [4, 1, 0], 'O8': [8, 0], 'O9': [9, 7, 0]}, 'G': {'G2': [2, 0], 'G4': [4, 1, 0], 'G5': [5, 3, 0], 'G6': [6, 1, 0], 'G8': [8, 0]}, 'B': {'B5': [5, 3, 0], 'B6': [6, 1, 0], 'B8': [8, 0]}, 'J': {'J2': [2, 0]}, 'E': {'E5': [5, 3, 0], 'E6': [6, 1, 0], 'E9': [9, 7, 0]}, 'Q': {'Q6': [6, 1, 0], 'Q9': [9, 7, 0]}, 'R': {'R5': [5, 3, 0]}, 'H': {'H2': [2, 0], 'H4': [4, 1, 0], 'H6': [6, 1, 0]}})\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from placement_aug import NEWcomputeCentralCosts\n",
    "\n",
    "with open('current_wl', 'rb') as workload:\n",
    "    wl = pickle.load(workload)\n",
    "costs = NEWcomputeCentralCosts(wl)\n",
    "print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<tree.SEQ object at 0x7f739aac1220>: ['P', <tree.SEQ object at 0x7f739a888dc0>], <tree.SEQ object at 0x7f739a888dc0>: ['I', 'O'], <tree.AND object at 0x7f7393f1adf0>: ['G', 'P', 'B', 'J'], <tree.AND object at 0x7f7393f1a1c0>: ['P', <tree.SEQ object at 0x7f7393f1a0d0>], <tree.SEQ object at 0x7f7393f1a0d0>: ['R', <tree.SEQ object at 0x7f7393fa6550>], <tree.SEQ object at 0x7f7393fa6550>: [<tree.AND object at 0x7f7393fa60d0>, 'E'], <tree.AND object at 0x7f7393fa60d0>: ['Q', 'H']}\n",
      "7\n",
      "Key: SEQ(P, I, O), value: ['P', <tree.SEQ object at 0x7f739a888dc0>]\n",
      "Key: SEQ(I, O), value: ['I', 'O']\n",
      "Key: AND(G, SEQ(P, B, J)), value: ['G', 'P', 'B', 'J']\n",
      "Key: AND(P, SEQ(E, AND(Q, R, H))), value: ['P', <tree.SEQ object at 0x7f7393f1a0d0>]\n",
      "Key: SEQ(E, AND(Q, R, H)), value: ['R', <tree.SEQ object at 0x7f7393fa6550>]\n",
      "Key: SEQ(E, AND(Q, H)), value: [<tree.AND object at 0x7f7393fa60d0>, 'E']\n",
      "Key: AND(Q, H), value: ['Q', 'H']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('curcombi', 'rb') as curcombi:\n",
    "    cc = pickle.load(curcombi)\n",
    "    print(cc)\n",
    "print(len(cc))\n",
    "for key, value in cc.items():\n",
    "    print(f\"Key: {key}, value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<tree.AND object at 0x7f73981f28e0>: (['P', 'H'], ['P', 9], 707228.5615905413), <tree.SEQ object at 0x7f739aac1bb0>: (['E', 'Q'], ['E', 6], 53.54975153928859), <tree.SEQ object at 0x7f7393f24430>: (['E', 'H'], ['E', 6], 351.0894377669257), <tree.AND object at 0x7f7393f24ac0>: (['Q', 'H'], ['Q', 4], 7.048862838444904), <tree.AND object at 0x7f7393f24700>: ([<tree.SEQ object at 0x7f7393f24430>, 'P'], ['P'], 926261.6482890521), <tree.AND object at 0x7f7393f24730>: ([<tree.AND object at 0x7f7393f24ac0>, 'P'], ['P'], 1204884.7378928768), <tree.SEQ object at 0x7f7393f243a0>: ([<tree.AND object at 0x7f7393f24ac0>, 'E'], ['E'], 444.00252888456055), <tree.AND object at 0x7f7398005f40>: (['P', <tree.SEQ object at 0x7f7393f243a0>], ['P', 9], 1247157.392315714), <tree.SEQ object at 0x7f7393fa6910>: (['R', <tree.SEQ object at 0x7f7393f243a0>], ['R', 0], 555.1012260658636), <tree.AND object at 0x7f7393fa6280>: (['P', <tree.SEQ object at 0x7f7393fa6910>], ['P', 9], 1248735.1124303725), <tree.SEQ object at 0x7f7393e404f0>: (['P', 'B'], ['P', 9], 848837.9197967114), <tree.SEQ object at 0x7f7393e40220>: (['P', 'B', 'J'], ['P', 9], 517177.2792405443), <tree.AND object at 0x7f7393e40700>: (['G', 'P', 'B', 'J'], ['P', 9], 1244136.6), <tree.SEQ object at 0x7f7393e40040>: (['I', 'O'], ['O', 6], 192.27479338897135), <tree.SEQ object at 0x7f7393e40d30>: (['P', <tree.SEQ object at 0x7f7393e40040>], ['P', 9], 1248340.3609871385)}\n",
      "Key: AND(P, H), value: (['P', 'H'], ['P', 9], 707228.5615905413)\n",
      "Key: SEQ(E, Q), value: (['E', 'Q'], ['E', 6], 53.54975153928859)\n",
      "Key: SEQ(E, H), value: (['E', 'H'], ['E', 6], 351.0894377669257)\n",
      "Key: AND(Q, H), value: (['Q', 'H'], ['Q', 4], 7.048862838444904)\n",
      "Key: AND(P, SEQ(E, H)), value: ([<tree.SEQ object at 0x7f7393f24430>, 'P'], ['P'], 926261.6482890521)\n",
      "Key: AND(P, AND(Q, H)), value: ([<tree.AND object at 0x7f7393f24ac0>, 'P'], ['P'], 1204884.7378928768)\n",
      "Key: SEQ(E, AND(Q, H)), value: ([<tree.AND object at 0x7f7393f24ac0>, 'E'], ['E'], 444.00252888456055)\n",
      "Key: AND(P, SEQ(E, AND(Q, H))), value: (['P', <tree.SEQ object at 0x7f7393f243a0>], ['P', 9], 1247157.392315714)\n",
      "Key: SEQ(E, AND(Q, R, H)), value: (['R', <tree.SEQ object at 0x7f7393f243a0>], ['R', 0], 555.1012260658636)\n",
      "Key: AND(P, SEQ(E, AND(Q, R, H))), value: (['P', <tree.SEQ object at 0x7f7393fa6910>], ['P', 9], 1248735.1124303725)\n",
      "Key: SEQ(P, B), value: (['P', 'B'], ['P', 9], 848837.9197967114)\n",
      "Key: SEQ(P, B, J), value: (['P', 'B', 'J'], ['P', 9], 517177.2792405443)\n",
      "Key: AND(G, SEQ(P, B, J)), value: (['G', 'P', 'B', 'J'], ['P', 9], 1244136.6)\n",
      "Key: SEQ(I, O), value: (['I', 'O'], ['O', 6], 192.27479338897135)\n",
      "Key: SEQ(P, I, O), value: (['P', <tree.SEQ object at 0x7f7393e40040>], ['P', 9], 1248340.3609871385)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('originalCombiDict', 'rb') as curcombi:\n",
    "    cc = pickle.load(curcombi)\n",
    "    print(cc)\n",
    "for key, value in cc.items():\n",
    "    print(f\"Key: {key}, value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>computePlanCosts_aug.py</h3>\n",
    "\n",
    "This file calculates all costs for all the binary files\n",
    "1. Starts off by Computing Central Costs for the Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'I', 'O']\n",
      "['G', 'P', 'B', 'J']\n",
      "['P', 'E', 'Q', 'R', 'H']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('current_wl', 'rb') as workload:\n",
    "    wl = pickle.load(workload)\n",
    "    \n",
    "for i in wl:\n",
    "    print(i.leafs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
